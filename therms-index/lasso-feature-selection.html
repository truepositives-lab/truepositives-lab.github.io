<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LASSO for Feature Selection</title>
  <script src="https://cdn.plot.ly/plotly-2.24.1.min.js"></script>
  <link rel="stylesheet" href="unified-styles.css">
</head>
<body>
  <a href="index.html" class="button" style="margin-bottom: 2rem;">‚Üê Back to Directory</a>
  <h2>LASSO (L1 Regularization) for Feature Selection</h2>

  <div class="card description">
    <h3>What is LASSO?</h3>
    <p><strong>LASSO</strong> (Least Absolute Shrinkage and Selection Operator) is a regression method that performs both regularization and feature selection by adding an L1 penalty term to the loss function. This penalty forces some coefficients to become exactly zero, effectively removing those features from the model.</p>
    <p>Unlike Ridge regression (L2), LASSO can produce sparse models by eliminating irrelevant features, making it excellent for feature selection in high-dimensional datasets.</p>
  </div>

  <div class="formula">
    <p><strong>LASSO Objective Function:</strong></p>
    <p>minimize: RSS + Œ± √ó Œ£|Œ≤·µ¢|</p>
    <p style="margin-top: 1rem;">Or equivalently:</p>
    <p><strong>minimize: Œ£(y·µ¢ - ≈∑·µ¢)¬≤ + Œ± √ó Œ£|Œ≤·µ¢|</strong></p>
    <p style="margin-top: 1rem;">Where:</p>
    <ul>
      <li><strong>RSS</strong> = Residual Sum of Squares</li>
      <li><strong>y·µ¢</strong> = actual target values</li>
      <li><strong>≈∑·µ¢</strong> = predicted values (Œ£ Œ≤‚±ºx·µ¢‚±º)</li>
      <li><strong>Œ≤·µ¢</strong> = feature coefficients</li>
      <li><strong>Œ±</strong> (alpha) = regularization strength (Œª in some texts)</li>
      <li><strong>|Œ≤·µ¢|</strong> = absolute value (L1 norm)</li>
    </ul>
  </div>

  <div class="card" style="background: #f0f9ff; border: 2px solid #0ea5e9;">
    <h3>üìä How LASSO Performs Feature Selection</h3>
    <ol style="line-height: 1.8;">
      <li>Add L1 penalty (sum of absolute coefficients) to the loss function</li>
      <li>As Œ± increases, more coefficients are pushed toward zero</li>
      <li>Some coefficients become exactly zero (unlike Ridge regression)</li>
      <li>Features with zero coefficients are automatically removed</li>
      <li>Remaining features are the selected ones</li>
    </ol>
  </div>

  <div class="scenario">
    <h3>üéØ Interactive LASSO Simulator</h3>
    <p>Adjust the regularization parameter Œ± to see how LASSO shrinks coefficients and performs feature selection.</p>

    <div class="control">
      <label for="alphaSlider">Regularization Strength (Œ±): <span id="alphaValue">0.1</span></label>
      <input type="range" id="alphaSlider" min="0" max="2" step="0.05" value="0.1"
             style="width: 100%;">
      <small>Œ± = 0 (no penalty) to Œ± = 2 (strong penalty)</small>
    </div>

    <div style="margin-top: 1rem;">
      <button class="button" onclick="loadScenario('lowCorrelation')">Low Correlation Features</button>
      <button class="button" onclick="loadScenario('highCorrelation')">High Correlation Features</button>
      <button class="button" onclick="loadScenario('mixed')">Mixed Importance</button>
    </div>
  </div>

  <div id="coefficientPath" style="width:100%;height:450px;margin: 2rem 0;"></div>

  <div class="highlight">
    <h3>üìà Current Model Statistics</h3>
    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 1rem; margin-top: 1rem;">
      <div class="card">
        <h4>Features Selected</h4>
        <p id="featuresSelected" style="font-size: 1.5rem; font-weight: bold; color: var(--success-color);">0</p>
      </div>
      <div class="card">
        <h4>Features Removed</h4>
        <p id="featuresRemoved" style="font-size: 1.5rem; font-weight: bold; color: var(--error-color);">0</p>
      </div>
      <div class="card">
        <h4>Sparsity</h4>
        <p id="sparsity" style="font-size: 1.5rem; font-weight: bold; color: var(--primary-color);">0%</p>
      </div>
      <div class="card">
        <h4>Avg |Coefficient|</h4>
        <p id="avgCoef" style="font-size: 1.5rem; font-weight: bold; color: var(--info-color);">0.00</p>
      </div>
    </div>
  </div>

  <div id="featureImportance" style="width:100%;height:400px;margin: 2rem 0;"></div>

  <div class="card" style="margin-top: 2rem;">
    <h3>üßÆ Feature Coefficients</h3>
    <div id="coefficientTable">
      <p>Adjust Œ± above to see coefficient values...</p>
    </div>
  </div>

  <div class="scenario">
    <h3>üîÑ LASSO vs Ridge vs Unregularized</h3>
    <p>Compare how different regularization methods handle feature selection:</p>
  </div>

  <div id="regularizationComparison" style="width:100%;height:400px;margin: 2rem 0;"></div>

  <div class="card" style="background: #fef3c7; border: 2px solid #f59e0b; margin-top: 2rem;">
    <h3>‚ö†Ô∏è Important Considerations</h3>
    <ul style="line-height: 1.8;">
      <li><strong>Feature Scaling:</strong> LASSO is sensitive to feature scale - always standardize!</li>
      <li><strong>Alpha Selection:</strong> Use cross-validation to choose optimal Œ±</li>
      <li><strong>Correlated Features:</strong> LASSO picks one arbitrarily from correlated group</li>
      <li><strong>Group Selection:</strong> Consider Elastic Net for grouped features</li>
      <li><strong>Interpretability:</strong> Sparse models are easier to interpret</li>
    </ul>
  </div>

  <div class="scenario" style="background: #f0fff0; border: 2px solid #4caf50; margin-top: 2rem;">
    <h3>üí° LASSO vs Other Methods</h3>
    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 2rem; margin-top: 1rem;">
      <div>
        <h4>LASSO (L1) ‚úì</h4>
        <ul>
          <li>Produces sparse models</li>
          <li>Coefficients = exactly 0</li>
          <li>Automatic feature selection</li>
          <li>Works with p > n</li>
          <li>Picks one from correlated group</li>
        </ul>
      </div>
      <div>
        <h4>Ridge (L2)</h4>
        <ul>
          <li>Dense models (all features)</li>
          <li>Coefficients ‚âà 0 (never exactly)</li>
          <li>No feature selection</li>
          <li>Works with p > n</li>
          <li>Keeps all correlated features</li>
        </ul>
      </div>
      <div>
        <h4>Elastic Net</h4>
        <ul>
          <li>Combines L1 + L2</li>
          <li>Some coefficients = 0</li>
          <li>Feature selection + grouping</li>
          <li>Best of both worlds</li>
          <li>Handles correlation better</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="card" style="margin-top: 2rem;">
    <h3>üêç Python Implementation</h3>
    <pre style="background: #1e293b; color: #e2e8f0; padding: 1rem; border-radius: var(--radius-md); overflow-x: auto;"><code>from sklearn.linear_model import Lasso, LassoCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import numpy as np

# Example data
X = np.random.randn(100, 10)  # 100 samples, 10 features
y = X[:, 0] + 2*X[:, 1] + np.random.randn(100)*0.1  # Only features 0,1 relevant

# IMPORTANT: Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Method 1: LASSO with fixed alpha
lasso = Lasso(alpha=0.1)
lasso.fit(X_scaled, y)

# Get selected features (non-zero coefficients)
selected = np.abs(lasso.coef_) > 1e-5
print(f"Coefficients: {lasso.coef_}")
print(f"Selected features: {np.where(selected)[0]}")
print(f"Number selected: {selected.sum()} / {X.shape[1]}")

# Method 2: LassoCV for automatic alpha selection
lasso_cv = LassoCV(cv=5, random_state=42)
lasso_cv.fit(X_scaled, y)
print(f"Optimal alpha: {lasso_cv.alpha_}")
print(f"CV score: {lasso_cv.score(X_scaled, y):.4f}")

# Method 3: Using SelectFromModel for feature selection
from sklearn.feature_selection import SelectFromModel
selector = SelectFromModel(Lasso(alpha=0.1), threshold=1e-5)
X_selected = selector.fit_transform(X_scaled, y)
print(f"Selected shape: {X_selected.shape}")
</code></pre>
  </div>

  <div class="scenario" style="margin-top: 2rem;">
    <h3>üéì Practice Exercise</h3>
    <button class="collapsible">Click to show exercise</button>
    <div class="content">
      <p style="margin-top: 1rem;"><strong>Exercise:</strong> You have a dataset with 50 features, but you suspect only 5 are truly predictive. You fit a LASSO model with different alpha values:</p>
      <ul>
        <li>Œ± = 0.01: 45 features selected, CV score = 0.82</li>
        <li>Œ± = 0.1: 12 features selected, CV score = 0.85</li>
        <li>Œ± = 0.5: 5 features selected, CV score = 0.84</li>
        <li>Œ± = 1.0: 2 features selected, CV score = 0.75</li>
      </ul>
      <p><strong>Questions:</strong></p>
      <ol>
        <li>Which alpha would you choose and why?</li>
        <li>What does the pattern tell you about feature importance?</li>
        <li>Why does performance drop at Œ± = 1.0?</li>
      </ol>
      <button class="collapsible" style="margin-top: 1rem;">Show solution</button>
      <div class="content">
        <p style="margin-top: 1rem;"><strong>Solution:</strong></p>
        <p>1. <strong>Choose Œ± = 0.1</strong> - Best CV score (0.85) with good sparsity (12 features)</p>
        <p>2. The pattern shows diminishing returns: 45‚Üí12 features gives +3% performance, suggesting ~12 features contain most information</p>
        <p>3. At Œ± = 1.0, too much regularization removes important features, causing underfitting</p>
        <p><strong>Key insight:</strong> Balance between sparsity and performance using cross-validation!</p>
      </div>
    </div>
  </div>

  <script>
    const alphaSlider = document.getElementById('alphaSlider');
    const alphaValue = document.getElementById('alphaValue');

    let currentScenario = 'mixed';
    const scenarios = {
      lowCorrelation: {
        trueCoefs: [2.5, -1.8, 1.2, -0.5, 0.3, 0, 0, 0, 0, 0],
        noise: 0.1
      },
      highCorrelation: {
        trueCoefs: [2.0, 1.9, 1.8, -0.2, 0, 0, 0, 0, 0, 0],
        noise: 0.2
      },
      mixed: {
        trueCoefs: [3.0, -2.0, 1.5, 0.8, -0.3, 0.1, 0, 0, 0, 0],
        noise: 0.15
      }
    };

    function simulateLasso(alpha, trueCoefs) {
      const shrinkage = 1 / (1 + alpha);
      const threshold = alpha * 0.5;

      return trueCoefs.map(coef => {
        const shrunk = coef * shrinkage;
        return Math.abs(shrunk) < threshold ? 0 : shrunk;
      });
    }

    function updateDisplay() {
      const alpha = parseFloat(alphaSlider.value);
      alphaValue.textContent = alpha.toFixed(2);

      const scenario = scenarios[currentScenario];
      const coefs = simulateLasso(alpha, scenario.trueCoefs);

      const nonZero = coefs.filter(c => Math.abs(c) > 0.001).length;
      const zero = coefs.length - nonZero;
      const sparsity = (zero / coefs.length * 100).toFixed(0);
      const avgCoef = coefs.reduce((sum, c) => sum + Math.abs(c), 0) / coefs.length;

      document.getElementById('featuresSelected').textContent = nonZero;
      document.getElementById('featuresRemoved').textContent = zero;
      document.getElementById('sparsity').textContent = sparsity + '%';
      document.getElementById('avgCoef').textContent = avgCoef.toFixed(3);

      createCoefficientPath(scenario.trueCoefs);
      createFeatureImportance(coefs);
      createCoefficientTable(coefs, alpha);
      createRegularizationComparison(scenario.trueCoefs, alpha);
    }

    function createCoefficientPath(trueCoefs) {
      const alphas = [];
      const paths = Array(trueCoefs.length).fill(null).map(() => []);

      for (let a = 0; a <= 2; a += 0.05) {
        alphas.push(a);
        const coefs = simulateLasso(a, trueCoefs);
        coefs.forEach((c, i) => paths[i].push(c));
      }

      const traces = paths.map((path, i) => ({
        x: alphas,
        y: path,
        type: 'scatter',
        mode: 'lines',
        name: `Feature ${i + 1}`,
        line: { width: 2 }
      }));

      const currentAlpha = parseFloat(alphaSlider.value);
      const verticalLine = {
        x: [currentAlpha, currentAlpha],
        y: [-4, 4],
        type: 'scatter',
        mode: 'lines',
        name: 'Current Œ±',
        line: { color: 'red', width: 3, dash: 'dash' }
      };

      const layout = {
        title: 'LASSO Regularization Path',
        xaxis: { title: 'Regularization Strength (Œ±)' },
        yaxis: { title: 'Coefficient Value' },
        showlegend: true,
        hovermode: 'closest'
      };

      Plotly.newPlot('coefficientPath', [...traces, verticalLine], layout, { responsive: true });
    }

    function createFeatureImportance(coefs) {
      const features = coefs.map((_, i) => `Feature ${i + 1}`);
      const absCoefs = coefs.map(c => Math.abs(c));

      const trace = {
        x: features,
        y: absCoefs,
        type: 'bar',
        marker: {
          color: coefs.map(c => Math.abs(c) < 0.001 ? '#ef4444' : '#10b981'),
          opacity: 0.7
        },
        text: coefs.map(c => c.toFixed(3)),
        textposition: 'auto'
      };

      const layout = {
        title: 'Feature Importance (|Coefficient|)',
        xaxis: { title: 'Feature' },
        yaxis: { title: 'Absolute Coefficient Value' },
        showlegend: false
      };

      Plotly.newPlot('featureImportance', [trace], layout, { responsive: true });
    }

    function createCoefficientTable(coefs, alpha) {
      const rows = coefs.map((c, i) => {
        const status = Math.abs(c) < 0.001 ?
          '<span style="color: var(--error-color); font-weight: bold;">Removed</span>' :
          '<span style="color: var(--success-color); font-weight: bold;">Selected</span>';

        return `
          <tr style="border-bottom: 1px solid var(--border-color);">
            <td style="padding: 0.5rem;">Feature ${i + 1}</td>
            <td style="padding: 0.5rem; text-align: right;">${c.toFixed(4)}</td>
            <td style="padding: 0.5rem; text-align: right;">${Math.abs(c).toFixed(4)}</td>
            <td style="padding: 0.5rem; text-align: center;">${status}</td>
          </tr>
        `;
      }).join('');

      const html = `
        <table style="width: 100%; border-collapse: collapse; margin-top: 1rem;">
          <thead style="background: var(--bg-tertiary);">
            <tr>
              <th style="padding: 0.75rem; text-align: left;">Feature</th>
              <th style="padding: 0.75rem; text-align: right;">Coefficient</th>
              <th style="padding: 0.75rem; text-align: right;">|Coefficient|</th>
              <th style="padding: 0.75rem; text-align: center;">Status</th>
            </tr>
          </thead>
          <tbody>
            ${rows}
          </tbody>
        </table>
        <p style="margin-top: 1rem; color: var(--text-secondary);">
          <small>Œ± = ${alpha.toFixed(2)} | Penalty = ${(alpha * coefs.reduce((sum, c) => sum + Math.abs(c), 0)).toFixed(3)}</small>
        </p>
      `;

      document.getElementById('coefficientTable').innerHTML = html;
    }

    function createRegularizationComparison(trueCoefs, alpha) {
      const features = trueCoefs.map((_, i) => `F${i + 1}`);

      const lassoCoefs = simulateLasso(alpha, trueCoefs).map(c => Math.abs(c));

      const ridgeShrinkage = 1 / (1 + alpha * 0.5);
      const ridgeCoefs = trueCoefs.map(c => Math.abs(c * ridgeShrinkage));

      const unregCoefs = trueCoefs.map(c => Math.abs(c));

      const trace1 = {
        x: features,
        y: lassoCoefs,
        type: 'bar',
        name: 'LASSO (L1)',
        marker: { color: '#3b82f6' }
      };

      const trace2 = {
        x: features,
        y: ridgeCoefs,
        type: 'bar',
        name: 'Ridge (L2)',
        marker: { color: '#10b981' }
      };

      const trace3 = {
        x: features,
        y: unregCoefs,
        type: 'bar',
        name: 'Unregularized',
        marker: { color: '#f59e0b' }
      };

      const layout = {
        title: 'Regularization Comparison',
        xaxis: { title: 'Feature' },
        yaxis: { title: 'Absolute Coefficient Value' },
        barmode: 'group',
        showlegend: true
      };

      Plotly.newPlot('regularizationComparison', [trace1, trace2, trace3], layout, { responsive: true });
    }

    function loadScenario(scenario) {
      currentScenario = scenario;
      updateDisplay();
    }

    alphaSlider.addEventListener('input', updateDisplay);

    const collapsibles = document.getElementsByClassName('collapsible');
    for (let i = 0; i < collapsibles.length; i++) {
      collapsibles[i].addEventListener('click', function() {
        this.classList.toggle('active');
        const content = this.nextElementSibling;
        if (content.style.maxHeight) {
          content.style.maxHeight = null;
        } else {
          content.style.maxHeight = content.scrollHeight + 'px';
        }
      });
    }

    updateDisplay();
  </script>
</body>
</html>
